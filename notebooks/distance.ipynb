{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "from shapely.geometry import MultiPoint\n",
    "import ast\n",
    "\n",
    "# our file structure:\n",
    "# wisd hackathon 2023 (root folder)\n",
    "# - /games (downloaded games from aws)\n",
    "# -- /gameid\n",
    "# --- {game_id}_e_t.csv (events and tracking data)\n",
    "# --- {game_id}_pyball.csv (events data)\n",
    "# - /metadata (downloaded metadata from aws)\n",
    "# - /play_coords (this is what backend will read from)\n",
    "# -- {game_id}_coords_by_player.json\n",
    "# - this notebook\n",
    "# i hope i wrote this in a way that makes sense!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_ids = ['0042100301', '0042100304', '0042100307', '0042100313', '0042100401', '0042100404', '0042100302', '0042100305', '0042100311',\n",
    "            '0042100314', '0042100402', '0042100405', '0042100303', '0042100306', '0042100312', '0042100315', '0042100403', '0042100406']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary mapping from game id to the joint_df for that game\n",
    "# reads all pyball csvs from all games, generated by get_pyball.ipynb\n",
    "shot_df_dict = {}\n",
    "for game_id in game_ids:\n",
    "    # read csv generated by get_pyball.ipynb, use first col as index\n",
    "    joint_df = pd.read_csv(\n",
    "        f'../games/{game_id}/{game_id}_pyball.csv', index_col=0)\n",
    "    shot_df_dict[game_id] = joint_df[joint_df['eventType']\n",
    "                                     == \"SHOT\"]  # RUN IF YOU ONLY WANT SHOTS\n",
    "    # shot_df_dict[game_id] = joint_df # RUN IF YOU WANT ALL EVENTS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convex hull testing for one game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'games/0042100301/0042100301_e_t.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m shots_tracking_df_dict \u001b[39m=\u001b[39m {}\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m game_id \u001b[39min\u001b[39;00m game_ids:\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m     \u001b[39m# run these lines if you already have {game_id}_e_t.csv, will be faster\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     joint_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\n\u001b[1;32m     11\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgames/\u001b[39;49m\u001b[39m{\u001b[39;49;00mgame_id\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mgame_id\u001b[39m}\u001b[39;49;00m\u001b[39m_e_t.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, index_col\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     12\u001b[0m     joint_df[\u001b[39m\"\u001b[39m\u001b[39mawayPlayers_tracking\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m joint_df[\u001b[39m\"\u001b[39m\u001b[39mawayPlayers_tracking\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mmap(\n\u001b[1;32m     13\u001b[0m         \u001b[39mlambda\u001b[39;00m x: \u001b[39meval\u001b[39m(x))\n\u001b[1;32m     14\u001b[0m     joint_df[\u001b[39m\"\u001b[39m\u001b[39mhomePlayers_tracking\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m joint_df[\u001b[39m\"\u001b[39m\u001b[39mhomePlayers_tracking\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mmap(\n\u001b[1;32m     15\u001b[0m         \u001b[39mlambda\u001b[39;00m x: \u001b[39meval\u001b[39m(x))\n",
      "File \u001b[0;32m~/Desktop/Code/wisd hackathon 2023/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Desktop/Code/wisd hackathon 2023/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/Code/wisd hackathon 2023/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Desktop/Code/wisd hackathon 2023/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/Code/wisd hackathon 2023/venv/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'games/0042100301/0042100301_e_t.csv'"
     ]
    }
   ],
   "source": [
    "# create dictionary of all game shots+tracking data\n",
    "# isolating the frames for each shot\n",
    "\n",
    "# inner join the shots_df from joint.csv\n",
    "# and the tracking data from that game\n",
    "shots_tracking_df_dict = {}\n",
    "for game_id in game_ids:\n",
    "\n",
    "    # run these lines if you already have {game_id}_e_t.csv, will be faster\n",
    "    joint_df = pd.read_csv(\n",
    "        f\"../games/{game_id}/{game_id}_e_t.csv\", index_col=0)\n",
    "    joint_df[\"awayPlayers_tracking\"] = joint_df[\"awayPlayers_tracking\"].map(\n",
    "        lambda x: eval(x))\n",
    "    joint_df[\"homePlayers_tracking\"] = joint_df[\"homePlayers_tracking\"].map(\n",
    "        lambda x: eval(x))\n",
    "    shots_tracking_df_dict[game_id] = joint_df[joint_df[\"eventType\"] == \"SHOT\"]\n",
    "\n",
    "    tracking_df = pd.read_json(\n",
    "        f\"../games/{game_id}/{game_id}_tracking.jsonl\", lines=True)\n",
    "\n",
    "    # merge and add suffixes to columns that originally belonged to events df and tracking df\n",
    "    shots_tracking_df_dict[game_id] = pd.merge(\n",
    "        shot_df_dict[game_id], tracking_df, on='wallClock', how='inner', suffixes=('_event', '_tracking'))\n",
    "\n",
    "    # I used this line to create csvs to plot players, must include all events, not just shots\n",
    "    shots_tracking_df_dict[game_id].to_csv(f'./games/{game_id}/{game_id}_e_t.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance3d(p1: list, p2: list) -> float:\n",
    "    x1, y1, z1 = p1\n",
    "    x2, y2, z2 = p2\n",
    "    return math.sqrt(math.pow(x2 - x1, 2) +\n",
    "                     math.pow(y2 - y1, 2) +\n",
    "                     math.pow(z2 - z1, 2) * 1.0)\n",
    "\n",
    "\n",
    "def away_or_home(row):\n",
    "    # did the away or home team take the shot\n",
    "    if (row['playerId'] in row['homePlayers_event']):\n",
    "        return 'home'\n",
    "    elif (row['playerId'] in row['awayPlayers_event']):\n",
    "        return 'away'\n",
    "    else:\n",
    "        print(f'ERROR: {row[\"EVENTNUM\"]}')\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_player_coords(row):\n",
    "    team = row['shotmaker_team']\n",
    "    for dict in row[f'{team}Players_tracking']:\n",
    "        if dict['playerId'] == row['playerId']:\n",
    "            return dict['xyz']\n",
    "\n",
    "\n",
    "def get_defender_distances(row):\n",
    "    # return a list of distances between each defender and the shotmaker\n",
    "    team = row['shotmaker_team']\n",
    "    shotmaker_coord = row['shotmaker_coord']\n",
    "    dist_arr = []\n",
    "    if team == 'away':\n",
    "        for entry in row['homePlayers_tracking']:\n",
    "            defender_coord = entry['xyz']\n",
    "            dist_arr.append(distance3d(shotmaker_coord, defender_coord))\n",
    "    elif team == 'home':\n",
    "        for entry in row['awayPlayers_tracking']:\n",
    "            defender_coord = entry['xyz']\n",
    "            dist_arr.append(distance3d(shotmaker_coord, defender_coord))\n",
    "    else:\n",
    "        print(f'ERROR: {row[\"EVENTNUM\"]}')\n",
    "        return None\n",
    "\n",
    "    return dist_arr\n",
    "\n",
    "\n",
    "def calc_hull(row):\n",
    "    # calculate hull area for away + home team\n",
    "    home_coords = [p['xyz'] for p in row['homePlayers_tracking']]\n",
    "    away_coords = [p['xyz'] for p in row['awayPlayers_tracking']]\n",
    "    home_multipoint = MultiPoint(home_coords)\n",
    "    home_convex_hull = home_multipoint.convex_hull\n",
    "    away_multipoint = MultiPoint(away_coords)\n",
    "    away_convex_hull = away_multipoint.convex_hull\n",
    "    row['home_hull'] = home_convex_hull.area\n",
    "    row['away_hull'] = away_convex_hull.area\n",
    "    return row\n",
    "\n",
    "\n",
    "def hull_distances(row):\n",
    "    shot_maker = row['shotmaker_team']\n",
    "    if shot_maker == 'home':\n",
    "        return row['home_hull'] - row['away_hull']\n",
    "    elif shot_maker == 'away':\n",
    "        return row['away_hull'] - row['home_hull']\n",
    "    else:\n",
    "        print(f\"ERROR: {row['EVENTNUM']}\")\n",
    "\n",
    "\n",
    "# create new columns on the shots_and_tracking_df\n",
    "for game_id in game_ids:\n",
    "    shots_tracking_df_dict[game_id] = shots_tracking_df_dict[game_id].apply(\n",
    "        calc_hull, axis=1)\n",
    "    # I decided to find if the shotmaker was on home or away first\n",
    "    # then I found the shotmaker's coordinates\n",
    "    # then I found the distance from all of the defenders\n",
    "    shots_tracking_df_dict[game_id]['shotmaker_team'] = shots_tracking_df_dict[game_id].apply(\n",
    "        lambda row: away_or_home(row), axis=1)\n",
    "    shots_tracking_df_dict[game_id]['shotmaker_coord'] = shots_tracking_df_dict[game_id].apply(\n",
    "        lambda row: get_player_coords(row), axis=1)\n",
    "    shots_tracking_df_dict[game_id]['defense_distance'] = shots_tracking_df_dict[game_id].apply(\n",
    "        lambda row: get_defender_distances(row), axis=1)\n",
    "    shots_tracking_df_dict[game_id]['hull_diff'] = shots_tracking_df_dict[game_id].apply(\n",
    "        lambda row: hull_distances(row), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crunch nums for hull diffs for home and away team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data_df = pd.read_csv('games_with_team_names.csv')\n",
    "\n",
    "hull_file = open(\"hull_info.txt\", \"w\")\n",
    "for game_id in game_ids:\n",
    "    # get row containing this game's metadata\n",
    "    game_data = game_data_df[game_data_df['nbaId'] == int(game_id)].iloc[0]\n",
    "    \n",
    "    home_name = game_data['homeTeamName']\n",
    "    away_name = game_data['awayTeamName']\n",
    "    hull_file.write(f\"GAME NBA ID: {game_id}\\n\")\n",
    "    hull_file.write(f\"HOME TEAM: {home_name}\\n\")\n",
    "    hull_file.write(f\"AWAY TEAM: {away_name}\\n\")\n",
    "\n",
    "    curr_df = shots_tracking_df_dict[game_id]\n",
    "    final_score = game_data[\"final_score\"]\n",
    "    hull_file.write(f\"FINAL SCORE: {away_name} {final_score} {home_name} \\n\")\n",
    "\n",
    "    home_makes_df = curr_df.loc[(curr_df['shotmaker_team']\n",
    "                                 == 'home') & (curr_df['HOMEDESCRIPTION'].str.contains(\"PTS\"))]\n",
    "    home_miss_df = curr_df.loc[(curr_df['shotmaker_team']\n",
    "                                == 'home') & (curr_df['HOMEDESCRIPTION'].str.contains(\"MISS\"))]\n",
    "    home_make_avg_hull_diff = round(home_makes_df['hull_diff'].mean(), 2)\n",
    "    home_miss_avg_hull_diff = round(home_miss_df['hull_diff'].mean(), 2)\n",
    "    home_avg_hull_diff = round(curr_df['hull_diff'].mean(), 2)\n",
    "    # hull_file.write(f'{home_name} avg_hull_diff: {home_avg_hull_diff}\\n')\n",
    "    hull_file.write(f'{home_name} make_avg_hull_diff: {home_make_avg_hull_diff}\\n')\n",
    "    hull_file.write(f'{home_name} miss_avg_hull_diff: {home_miss_avg_hull_diff}\\n')\n",
    "\n",
    "    away_makes_df = curr_df.loc[(curr_df['shotmaker_team']\n",
    "                                 == 'away') & (curr_df['VISITORDESCRIPTION'].str.contains(\"PTS\"))]\n",
    "    away_miss_df = curr_df.loc[(curr_df['shotmaker_team']\n",
    "                                == 'away') & (curr_df['VISITORDESCRIPTION'].str.contains(\"MISS\"))]\n",
    "    away_make_avg_hull_diff = round(away_makes_df['hull_diff'].mean(), 3)\n",
    "    away_miss_avg_hull_diff = round(away_miss_df['hull_diff'].mean(), 3)\n",
    "    away_avg_hull_diff = round(curr_df['hull_diff'].mean(), 2)\n",
    "    # hull_file.write(f'{away_name} avg_hull_diff: {away_avg_hull_diff}\\n')\n",
    "    hull_file.write(f'{away_name} make_avg_hull_diff: {away_make_avg_hull_diff}\\n')\n",
    "    hull_file.write(f'{away_name} miss_avg_hull_diff: {away_miss_avg_hull_diff}\\n')\n",
    "    hull_file.write(\"\\n\\n\")\n",
    "\n",
    "hull_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# made_dist, miss_dist: average distance from shooter to closest defensive player\n",
    "# made_off_hull: avg hull area of the offensive team on makes\n",
    "# miss_off_hull: avg hull area of the offensive team on misses\n",
    "\n",
    "# globals\n",
    "global_dict = {'made_dist': [],  'miss_dist': [], 'diff': [], 'made_off_hull': [], 'made_def_hull': [\n",
    "], 'miss_off_hull': [], 'miss_def_hull': []}\n",
    "\n",
    "\n",
    "def shot_made(row) -> bool:\n",
    "    # determine if the player made the shot or not, required: row['shotmaker_team']\n",
    "    description = \"\"\n",
    "    if row['shotmaker_team'] == \"away\":\n",
    "        description = \"VISITORDESCRIPTION\"\n",
    "    elif row['shotmaker_team'] == \"home\":\n",
    "        description = \"HOMEDESCRIPTION\"\n",
    "    else:\n",
    "        print(f\"ERROR: {row['EVENTNUM']}\")\n",
    "        return\n",
    "    if isinstance(row[description], str) and \"MISS\" in row[description]:\n",
    "        return False\n",
    "        # player missed the shot\n",
    "    elif isinstance(row[description], str) and \"PTS\" in row[description]:\n",
    "        return True\n",
    "\n",
    "\n",
    "def calculate_aggregates(row, agg_dict):\n",
    "    if shot_made(row):\n",
    "        # add the distance from the shotmaker and the closest defender\n",
    "        agg_dict['made_dist'].append(min(row['defense_distance']))\n",
    "        if row['shotmaker_team'] == \"away\":\n",
    "            agg_dict['made_off_hull'].append(row['away_hull'])\n",
    "            agg_dict['made_def_hull'].append(row['home_hull'])\n",
    "        elif row['shotmaker_team'] == \"home\":\n",
    "            agg_dict['made_off_hull'].append(row['home_hull'])\n",
    "            agg_dict['made_def_hull'].append(row['away_hull'])\n",
    "    else:\n",
    "        agg_dict['miss_dist'].append(min(row['defense_distance']))\n",
    "        if row['shotmaker_team'] == \"away\":\n",
    "            agg_dict['miss_off_hull'].append(row['away_hull'])\n",
    "            agg_dict['miss_def_hull'].append(row['home_hull'])\n",
    "        elif row['shotmaker_team'] == \"home\":\n",
    "            agg_dict['miss_off_hull'].append(row['home_hull'])\n",
    "            agg_dict['miss_def_hull'].append(row['away_hull'])\n",
    "\n",
    "\n",
    "avgs = []  # list of all games' stats to create df with\n",
    "\n",
    "for game_id in game_ids:\n",
    "    game_stats = {'made_dist': [], 'miss_dist': [], 'diff': [0], 'made_off_hull': [], 'made_def_hull': [\n",
    "    ], 'miss_off_hull': [], 'miss_def_hull': []}  # FOR THIS GAME ONLY\n",
    "    shots_tracking_df_dict[game_id].apply(\n",
    "        lambda row: calculate_aggregates(row, game_stats), axis=1)\n",
    "    for k, v in game_stats.items():\n",
    "        if k == 'diff':\n",
    "            continue\n",
    "        game_stats[k] = sum(v) / len(v)  # calculate avg of this game's stats\n",
    "        global_dict[k].append(game_stats[k])\n",
    "    game_stats['diff'] = game_stats['made_dist'] - game_stats['miss_dist']\n",
    "    global_dict['diff'].append(game_stats['diff'])\n",
    "    this_avgs = list(game_stats.values())\n",
    "    this_avgs.insert(0, game_id)\n",
    "    avgs.append(this_avgs)\n",
    "\n",
    "for k, v in global_dict.items():\n",
    "    global_dict[k] = sum(v) / len(v)\n",
    "global_avg = list(global_dict.values())\n",
    "global_avg.insert(0, \"AVG\")\n",
    "avgs.append(global_avg)\n",
    "\n",
    "avg_df = pd.DataFrame(avgs, columns=['game_id', 'made_dist', 'miss_dist', 'diff', 'made_off_hull',\n",
    "                      'made_def_hull',  'miss_off_hull', 'miss_def_hull'])\n",
    "avg_df.to_csv('avg.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate top ten most spaced out plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting plays by greatest difference between the shotmaker team and the other team\n",
    "\n",
    "\n",
    "def calc_coords(row, team):\n",
    "    player_coords = []\n",
    "    for player in row[f'{team}Players_tracking']:\n",
    "        player_coords.append(player['xyz'])\n",
    "    return player_coords\n",
    "\n",
    "\n",
    "for game_id in game_ids:\n",
    "    shots_tracking_df_dict[game_id]['home_coords'] = shots_tracking_df_dict[game_id].apply(\n",
    "        lambda row: calc_coords(row, 'home'), axis=1)\n",
    "    shots_tracking_df_dict[game_id]['away_coords'] = shots_tracking_df_dict[game_id].apply(\n",
    "        lambda row: calc_coords(row, 'away'), axis=1)\n",
    "    shots_tracking_df_dict[game_id] = shots_tracking_df_dict[game_id].sort_values(\n",
    "        by='hull_diff', ascending=False)\n",
    "\n",
    "    df = shots_tracking_df_dict[game_id].head(10)\n",
    "    # df = df[['home_coords', 'away_coords', 'wallClock', 'ball', 'hull_diff']]\n",
    "    df.to_csv(f'../games/{game_id}/{game_id}_top_ten.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the data for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each game, we identify the 10 best shots and then retrieve the data for the entire play\n",
    "# the play is then aggregated by player and added \n",
    "\n",
    "for game_id in game_ids:\n",
    "    e_t_df = pd.read_csv(f'../games/{game_id}/{game_id}_e_t.csv', index_col=0)\n",
    "    top_ten_df = pd.read_csv(f'../games/{game_id}/{game_id}_top_ten.csv', index_col=0)\n",
    "\n",
    "    shot_rank = 1 # rank of shot (1-10)\n",
    "    top_ten_play_coords_by_player = {}\n",
    "    for clock in top_ten_df['wallClock']:\n",
    "        # row # of the shot in e_t_df:\n",
    "        shot_index = e_t_df[(e_t_df['wallClock'] == clock) & (e_t_df['eventType'] == \"SHOT\")].index[0]\n",
    "\n",
    "        # FOR RIGHT NOW, skipping the rest of the loop if the shotclock is 0, because I'm not sure why that's happening\n",
    "        if e_t_df.loc[shot_index, 'shotClock_tracking'] == 0:\n",
    "            continue\n",
    "\n",
    "        # index starts when the shotclock is 24, or close to 24, i.e. when the time \"starts over\"\n",
    "        start_index = shot_index\n",
    "        while start_index > 0:\n",
    "            curr_shotclock = e_t_df.loc[start_index, 'shotClock_tracking']\n",
    "            prev_shotclock = e_t_df.loc[start_index - 1, 'shotClock_tracking']\n",
    "            \n",
    "            # when the shot clock is greater than the previous row, we know it \"started over\"\n",
    "            if curr_shotclock > prev_shotclock:\n",
    "                break\n",
    "            start_index -= 1\n",
    "            \n",
    "        # the coordinates for each play start when the shotclock beings and end when the shot is taken\n",
    "        play_coords_df = e_t_df.iloc[start_index:shot_index+1]\n",
    "\n",
    "        play_coords_df = play_coords_df[['eventType', 'homePlayers_tracking', 'awayPlayers_tracking', 'ball', 'shotClock_tracking']]\n",
    "\n",
    "        # string to JSON\n",
    "        play_coords_df['homePlayers_tracking'] = play_coords_df['homePlayers_tracking'].apply(ast.literal_eval)\n",
    "        play_coords_df['awayPlayers_tracking'] = play_coords_df['awayPlayers_tracking'].apply(ast.literal_eval)\n",
    "        play_coords_df['ball'] = play_coords_df['ball'].apply(\n",
    "            ast.literal_eval)\n",
    "\n",
    "        # method to aggregate the data for visualization, organizing by player instead of by play\n",
    "        def coords_by_player(team, color):\n",
    "            player_dict = {}\n",
    "\n",
    "            for _, row in play_coords_df.iterrows():\n",
    "                tracking_info = row[f'{team}Players_tracking']\n",
    "                \n",
    "                for player in tracking_info:\n",
    "                    jersey = player['jersey']\n",
    "                    playerId = player['playerId']\n",
    "                    xyz = player['xyz']\n",
    "                    \n",
    "                    # Append the coords to the list for the corresponding player\n",
    "                    if (jersey, playerId) not in player_dict:\n",
    "                        player_dict[(jersey, playerId)] = []\n",
    "                    player_dict[(jersey, playerId)].append(xyz)\n",
    "\n",
    "            # Converting the dictionary to a list of dictionaries for each player\n",
    "            all_coords_list = [{'type': team, 'number': jersey, 'color': color, 'coords': xyz_list} for (jersey, playerId), xyz_list in player_dict.items()]\n",
    "            return all_coords_list\n",
    "        \n",
    "        # method to aggregate the data for visualization, organizing by player instead of by play\n",
    "        def ball_coords():\n",
    "            xyz_list = []\n",
    "            for _, row in play_coords_df.iterrows():\n",
    "                tracking_info = row['ball']\n",
    "                xyz_list.append(tracking_info)\n",
    "            # Converting the dictionary to a list of dictionaries for each player\n",
    "            all_coords_list = [{'type': 'ball', 'color': 'orange', 'coords': xyz_list}]\n",
    "            return all_coords_list\n",
    "\n",
    "        # dictionary mapping from the gameClock of the best shot to the players and their location data\n",
    "        top_ten_play_coords_by_player[shot_rank] = coords_by_player('home', 'blue') + coords_by_player('away', 'red') + ball_coords()\n",
    "        shot_rank +=1\n",
    "    with open(f\"../play_coords/{game_id}_coords_by_player.json\", \"w\") as outfile:\n",
    "        json.dump(top_ten_play_coords_by_player, outfile)\n",
    "    # print(\"GAME\", game_id, top_ten_play_coords_by_player)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
